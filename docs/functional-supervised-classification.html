<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Functional Supervised Classification | Functional Data Analysis using fda.usc and fda.clust packages</title>
  <meta name="description" content="Functional Data Analysis, Regression, Classification and Clustering using fda.usc and fda.clust packages" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Functional Supervised Classification | Functional Data Analysis using fda.usc and fda.clust packages" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Functional Data Analysis, Regression, Classification and Clustering using fda.usc and fda.clust packages" />
  <meta name="github-repo" content="moviedo5/bookdown_fda_clust" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Functional Supervised Classification | Functional Data Analysis using fda.usc and fda.clust packages" />
  
  <meta name="twitter:description" content="Functional Data Analysis, Regression, Classification and Clustering using fda.usc and fda.clust packages" />
  

<meta name="author" content="Manuel Oviedo de la Fuente (Universidade of A Coruña, CITIC, MODES RG) and Manuel Febrero-Bande (Universidade de Santaigo de Compostela, MODESTYA RG)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression.html"/>
<link rel="next" href="variable-selection.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Escritura de libros con bookdown</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cran-task-view"><i class="fa fa-check"></i>CRAN Task View</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#functional-data-analysis-in-r"><i class="fa fa-check"></i>Functional Data Analysis in R</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#installation"><i class="fa fa-check"></i>Installation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#quick-start"><i class="fa fa-check"></i>Quick Start</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="definition.html"><a href="definition.html"><i class="fa fa-check"></i><b>1</b> Functional Data: Definition, Representation and Manipulation</a>
<ul>
<li class="chapter" data-level="1.1" data-path="definition.html"><a href="definition.html#some-definitions-of-functional-data"><i class="fa fa-check"></i><b>1.1</b> Some definitions of Functional Data</a></li>
<li class="chapter" data-level="1.2" data-path="definition.html"><a href="definition.html#in-fda.usc-the-data-are-curves"><i class="fa fa-check"></i><b>1.2</b> In fda.usc: ``The data are curves’’</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="definition.html"><a href="definition.html#definition-of-fdata-class-in-r"><i class="fa fa-check"></i><b>1.2.1</b> Definition of –fdata– class in R</a></li>
<li class="chapter" data-level="1.2.2" data-path="definition.html"><a href="definition.html#some-utilities-of-fda.usc-package"><i class="fa fa-check"></i><b>1.2.2</b> Some utilities of fda.usc package</a></li>
<li class="chapter" data-level="1.2.3" data-path="definition.html"><a href="definition.html#definition-of-ldata-class-in-r"><i class="fa fa-check"></i><b>1.2.3</b> Definition of –ldata– class in R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="definition.html"><a href="definition.html#resume-by-smoothing"><i class="fa fa-check"></i><b>1.3</b> Resume by smoothing</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="definition.html"><a href="definition.html#derivatives"><i class="fa fa-check"></i><b>1.3.1</b> Derivatives</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="definition.html"><a href="definition.html#semi-metric-as-classification-rule"><i class="fa fa-check"></i><b>1.4</b> Semi-metric as classification rule</a></li>
<li class="chapter" data-level="1.5" data-path="definition.html"><a href="definition.html#correlation-distances-szekely2007"><i class="fa fa-check"></i><b>1.5</b> Correlation Distances <span class="citation">(G. J. Székely, Rizzo, and Bakirov 2007)</span></a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="definition.html"><a href="definition.html#depth-for-functional-data"><i class="fa fa-check"></i><b>1.5.1</b> Depth for functional data</a></li>
<li class="chapter" data-level="1.5.2" data-path="definition.html"><a href="definition.html#depth-and-distances-for-multivariate-functional-data-cuesta2017hbox"><i class="fa fa-check"></i><b>1.5.2</b> Depth (and distances) for multivariate functional data <span class="citation">(J. A. Cuesta-Albertos, Febrero-Bande, and Oviedo de la Fuente 2017)</span></a></li>
<li class="chapter" data-level="1.5.3" data-path="definition.html"><a href="definition.html#outliers-detection"><i class="fa fa-check"></i><b>1.5.3</b> Outliers detection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>2</b> Functional Regression Model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="regression.html"><a href="regression.html#functional-linear-model-flr-with-basis-representation"><i class="fa fa-check"></i><b>2.1</b> Functional linear model (FLR) with basis representation</a></li>
<li class="chapter" data-level="2.2" data-path="regression.html"><a href="regression.html#flm-with-functional-and-non-functional-covariates"><i class="fa fa-check"></i><b>2.2</b> FLM with functional and non functional covariates</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="regression.html"><a href="regression.html#predict-method-for-functional-regression-model"><i class="fa fa-check"></i><b>2.2.1</b> Predict method for functional regression model</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="regression.html"><a href="regression.html#other-procedures"><i class="fa fa-check"></i><b>2.3</b> Other procedures</a></li>
<li class="chapter" data-level="2.4" data-path="regression.html"><a href="regression.html#non-linear-model-fv2006"><i class="fa fa-check"></i><b>2.4</b> Non Linear Model <span class="citation">(Frédéric Ferraty and Vieu 2006)</span></a></li>
<li class="chapter" data-level="2.5" data-path="regression.html"><a href="regression.html#semi-linear-model-aneiros2005"><i class="fa fa-check"></i><b>2.5</b> Semi Linear Model <span class="citation">(Aneiros-Pérez and Vieu 2006)</span></a></li>
<li class="chapter" data-level="2.6" data-path="regression.html"><a href="regression.html#generalized-linear-models-muller2005generalized"><i class="fa fa-check"></i><b>2.6</b> Generalized Linear Models <span class="citation">(Müller and Stadtmüller 2005)</span></a></li>
<li class="chapter" data-level="2.7" data-path="regression.html"><a href="regression.html#generalized-functional-additive-model"><i class="fa fa-check"></i><b>2.7</b> Generalized Functional Additive Model</a></li>
<li class="chapter" data-level="2.8" data-path="regression.html"><a href="regression.html#functional-gls-model"><i class="fa fa-check"></i><b>2.8</b> Functional GLS model</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="regression.html"><a href="regression.html#dependent-data-example"><i class="fa fa-check"></i><b>2.8.1</b> Dependent data example,</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="regression.html"><a href="regression.html#functional-response-model"><i class="fa fa-check"></i><b>2.9</b> Functional Response Model</a></li>
<li class="chapter" data-level="2.10" data-path="regression.html"><a href="regression.html#other-models"><i class="fa fa-check"></i><b>2.10</b> Other Models:</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html"><i class="fa fa-check"></i><b>3</b> Functional Supervised Classification</a>
<ul>
<li class="chapter" data-level="3.1" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#logistic-regression-model-glm-classif.glm"><i class="fa fa-check"></i><b>3.1</b> Logistic Regression Model (GLM): <code>classif.glm</code></a></li>
<li class="chapter" data-level="3.2" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#generalized-additive-models-gam-classif.gsam-and-classif.gkam"><i class="fa fa-check"></i><b>3.2</b> Generalized Additive Models (GAM): <code>classif.gsam</code> and <code>classif.gkam</code></a></li>
<li class="chapter" data-level="3.3" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#nonparametric-classification-methods-classif.knn-and-classif.np-ferraty2003"><i class="fa fa-check"></i><b>3.3</b> Nonparametric classification methods: <code>classif.knn</code> and <code>classif.np</code> <span class="citation">(Frédéric Ferraty and Vieu 2003)</span></a></li>
<li class="chapter" data-level="3.4" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#maximum-depth-classif.depth-li2012"><i class="fa fa-check"></i><b>3.4</b> Maximum depth: <code>classif.depth</code> <span class="citation">(Li, Cuesta-Albertos, and Liu 2012)</span></a></li>
<li class="chapter" data-level="3.5" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#the-ddgclassifier-classif.dd-cuesta2017hbox"><i class="fa fa-check"></i><b>3.5</b> The DD<span class="math inline">\(^G\)</span>–classifier <code>classif.DD</code> <span class="citation">(J. A. Cuesta-Albertos, Febrero-Bande, and Oviedo de la Fuente 2017)</span></a></li>
<li class="chapter" data-level="3.6" data-path="functional-supervised-classification.html"><a href="functional-supervised-classification.html#classifiers-adapted-from-multivariate-framework"><i class="fa fa-check"></i><b>3.6</b> Classifiers adapted from Multivariate Framework</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="variable-selection.html"><a href="variable-selection.html"><i class="fa fa-check"></i><b>4</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="4.1" data-path="variable-selection.html"><a href="variable-selection.html#functiondal-regression-with-points-of-impact"><i class="fa fa-check"></i><b>4.1</b> Functiondal regression with points of impact</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="variable-selection.html"><a href="variable-selection.html#state-of-art"><i class="fa fa-check"></i><b>4.1.1</b> State of Art</a></li>
<li class="chapter" data-level="4.1.2" data-path="variable-selection.html"><a href="variable-selection.html#local-maxima-distance-correlation-approach-lmdc-ordonez2018"><i class="fa fa-check"></i><b>4.1.2</b> Local maxima distance correlation approach (LMDC), <span class="citation">(Ordóñez et al. 2018)</span></a></li>
<li class="chapter" data-level="4.1.3" data-path="variable-selection.html"><a href="variable-selection.html#lmdc-algorithm-lmdc.select-function"><i class="fa fa-check"></i><b>4.1.3</b> LMDC Algorithm: <code>LMDC.select()</code> function</a></li>
<li class="chapter" data-level="4.1.4" data-path="variable-selection.html"><a href="variable-selection.html#lmdc-algorithm-lmdc.regre-function"><i class="fa fa-check"></i><b>4.1.4</b> LMDC Algorithm: <code>LMDC.regre()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="variable-selection.html"><a href="variable-selection.html#variable-selection-in-functional-regression"><i class="fa fa-check"></i><b>4.2</b> Variable selection in functional regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="variable-selection.html"><a href="variable-selection.html#state-of-art-1"><i class="fa fa-check"></i><b>4.2.1</b> State of Art</a></li>
<li class="chapter" data-level="4.2.2" data-path="variable-selection.html"><a href="variable-selection.html#algorithm"><i class="fa fa-check"></i><b>4.2.2</b> Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="variable-selection.html"><a href="variable-selection.html#binary-classification-example"><i class="fa fa-check"></i><b>4.3</b> Binary classification example</a></li>
<li class="chapter" data-level="4.4" data-path="variable-selection.html"><a href="variable-selection.html#hyperspectral-images-example"><i class="fa fa-check"></i><b>4.4</b> Hyperspectral images example</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="variable-selection.html"><a href="variable-selection.html#hyperspectral-data-set-pavia-university"><i class="fa fa-check"></i><b>4.4.1</b> Hyperspectral Data set: Pavia University</a></li>
<li class="chapter" data-level="4.4.2" data-path="variable-selection.html"><a href="variable-selection.html#hyperspectral-images"><i class="fa fa-check"></i><b>4.4.2</b> Hyperspectral images</a></li>
<li class="chapter" data-level="4.4.3" data-path="variable-selection.html"><a href="variable-selection.html#pravia-univ.-results"><i class="fa fa-check"></i><b>4.4.3</b> Pravia Univ. Results</a></li>
<li class="chapter" data-level="4.4.4" data-path="variable-selection.html"><a href="variable-selection.html#functional-data-example"><i class="fa fa-check"></i><b>4.4.4</b> Functional data example</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="variable-selection.html"><a href="variable-selection.html#optimum-multiscale-selection-in-3d-point-cloud-classification-oviedo2021distance"><i class="fa fa-check"></i><b>4.5</b> Optimum Multiscale Selection in 3D Point Cloud Classification <span class="citation">(Oviedo-de la Fuente et al. 2021)</span></a></li>
<li class="chapter" data-level="4.6" data-path="variable-selection.html"><a href="variable-selection.html#model-comparison"><i class="fa fa-check"></i><b>4.6</b> Model Comparison</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="functional-clustering.html"><a href="functional-clustering.html"><i class="fa fa-check"></i><b>5</b> Functional Clustering</a>
<ul>
<li class="chapter" data-level="5.1" data-path="functional-clustering.html"><a href="functional-clustering.html#r-packages-for-clustering"><i class="fa fa-check"></i><b>5.1</b> R Packages for Clustering</a></li>
<li class="chapter" data-level="5.2" data-path="functional-clustering.html"><a href="functional-clustering.html#r-packages-for-clustering-functional-data"><i class="fa fa-check"></i><b>5.2</b> R Packages for Clustering Functional Data</a></li>
<li class="chapter" data-level="5.3" data-path="functional-clustering.html"><a href="functional-clustering.html#k-means-clustering-for-functional-data"><i class="fa fa-check"></i><b>5.3</b> K-Means Clustering for Functional Data</a></li>
<li class="chapter" data-level="5.4" data-path="functional-clustering.html"><a href="functional-clustering.html#functional-data-clustering-with-dbscan-fdbscan"><i class="fa fa-check"></i><b>5.4</b> Functional Data Clustering with DBSCAN (<code>fdbscan</code>)</a></li>
<li class="chapter" data-level="5.5" data-path="functional-clustering.html"><a href="functional-clustering.html#functional-data-clustering-with-mean-shift-fmeanshift"><i class="fa fa-check"></i><b>5.5</b> Functional Data Clustering with Mean Shift (<code>fmeanshift</code>)</a></li>
<li class="chapter" data-level="5.6" data-path="functional-clustering.html"><a href="functional-clustering.html#multivariate-functional-data-clustering"><i class="fa fa-check"></i><b>5.6</b> Multivariate Functional Data Clustering</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="functional-clustering.html"><a href="functional-clustering.html#hierarchical-clustering-with-mfhclust"><i class="fa fa-check"></i><b>5.6.1</b> Hierarchical Clustering with <code>mfhclust()</code></a></li>
<li class="chapter" data-level="5.6.2" data-path="functional-clustering.html"><a href="functional-clustering.html#k-means-clustering-with-mfkmeans"><i class="fa fa-check"></i><b>5.6.2</b> K-means Clustering with mfkmeans()</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="functional-clustering.html"><a href="functional-clustering.html#cluster-validation-measures"><i class="fa fa-check"></i><b>5.7</b> Cluster Validation Measures</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="functional-clustering.html"><a href="functional-clustering.html#silhouette-index"><i class="fa fa-check"></i><b>5.7.1</b> Silhouette Index</a></li>
<li class="chapter" data-level="5.7.2" data-path="functional-clustering.html"><a href="functional-clustering.html#dunn-index"><i class="fa fa-check"></i><b>5.7.2</b> Dunn Index</a></li>
<li class="chapter" data-level="5.7.3" data-path="functional-clustering.html"><a href="functional-clustering.html#davies-bouldin-index"><i class="fa fa-check"></i><b>5.7.3</b> Davies-Bouldin Index</a></li>
<li class="chapter" data-level="5.7.4" data-path="functional-clustering.html"><a href="functional-clustering.html#calinski-harabasz-index"><i class="fa fa-check"></i><b>5.7.4</b> Calinski-Harabasz Index</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="functional-clustering.html"><a href="functional-clustering.html#conclusions-and-future-work"><i class="fa fa-check"></i>Conclusions and Future Work</a></li>
<li class="chapter" data-level="" data-path="functional-clustering.html"><a href="functional-clustering.html#chapter-references"><i class="fa fa-check"></i>Chapter references</a></li>
<li class="chapter" data-level="" data-path="functional-clustering.html"><a href="functional-clustering.html#funding-and-financial-support"><i class="fa fa-check"></i>Funding and Financial Support</a></li>
<li class="chapter" data-level="" data-path="functional-clustering.html"><a href="functional-clustering.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publicado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Functional Data Analysis using fda.usc and fda.clust packages</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="functional-supervised-classification" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Functional Supervised Classification<a href="functional-supervised-classification.html#functional-supervised-classification" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- 
\newcommand{\lrp}[1]{\left(#1\right)}
\newcommand{\lrc}[1]{\left[#1\right]}
\newcommand{\lrb}[1]{\left\{#1\right\}}

%\VignetteEngine{knitr::knitr} 
%\VignetteIndexEntry{}
-->
<p>This section describes the usage of functional classification using fda.usc package in R.</p>
<p>Let a sample <span class="math inline">\((\mathcal{X},Y)\in E \times \mathbb{G}={1,\cdots,G}\)</span>.</p>
<p>Aim: How predict the class <span class="math inline">\(g\)</span> of Y (categorical variable) given a functional variable <span class="math inline">\(\mathcal{X}\)</span></p>
<p>Bayes rule: Estimate the posterior probability of belonging to each group:</p>
<p><span class="math display">\[p_g(X)=\mathbb{P}(Y=g | \mathcal{X}=\chi)=\mathbb{E}(1_{Y=g} |\mathcal{X}=\chi)\]</span></p>
<p>The predicted class is given by the Bayes rule,</p>
<p><span class="math display">\[\hat{Y}=\arg \max_{g\in \mathbb{G}} \hat{p}_g(\chi)\]</span></p>
<p>The package allows the estimation of the groups in a training set of functional data by</p>
<ul>
<li>Logistic Classifier (linear model): <code>classif.glm</code></li>
<li>Logistic Classifier (additive model): <code>classif.gsam</code> and <code>classif.gkam</code></li>
<li>k-Nearest Neighbor Classifier: <code>classif.knn</code></li>
<li>Kernel Classifier: <code>classif.kernel</code></li>
<li>Distance Classifier: `classif.distv</li>
<li>Maximum Depth Classifier: <code>classif.depth</code></li>
<li>DD Clasisifier: <code>classif.DD</code></li>
</ul>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="functional-supervised-classification.html#cb156-1" tabindex="-1"></a><span class="fu">library</span>(fda.usc)</span>
<span id="cb156-2"><a href="functional-supervised-classification.html#cb156-2" tabindex="-1"></a><span class="fu">data</span>(tecator)</span>
<span id="cb156-3"><a href="functional-supervised-classification.html#cb156-3" tabindex="-1"></a>x<span class="ot">=</span>tecator<span class="sc">$</span>absorp.fdata</span>
<span id="cb156-4"><a href="functional-supervised-classification.html#cb156-4" tabindex="-1"></a>tecator<span class="sc">$</span>y<span class="sc">$</span>Fat<span class="ot">&lt;-</span><span class="fu">ifelse</span>(tecator<span class="sc">$</span>y<span class="sc">$</span>Fat<span class="sc">&gt;</span><span class="dv">20</span>,<span class="dv">1</span>,<span class="dv">0</span>)</span>
<span id="cb156-5"><a href="functional-supervised-classification.html#cb156-5" tabindex="-1"></a></span>
<span id="cb156-6"><a href="functional-supervised-classification.html#cb156-6" tabindex="-1"></a>x.d1<span class="ot">&lt;-</span><span class="fu">fdata.deriv</span>(x)</span>
<span id="cb156-7"><a href="functional-supervised-classification.html#cb156-7" tabindex="-1"></a>dataf<span class="ot">=</span><span class="fu">as.data.frame</span>(tecator<span class="sc">$</span>y)</span>
<span id="cb156-8"><a href="functional-supervised-classification.html#cb156-8" tabindex="-1"></a>ldat <span class="ot">=</span> <span class="fu">ldata</span>(<span class="st">&quot;df&quot;</span><span class="ot">=</span>dataf,<span class="st">&quot;x&quot;</span><span class="ot">=</span>x,<span class="st">&quot;x.d1&quot;</span><span class="ot">=</span>x.d1)</span>
<span id="cb156-9"><a href="functional-supervised-classification.html#cb156-9" tabindex="-1"></a>ycat<span class="ot">&lt;-</span>ldat<span class="sc">$</span>df<span class="sc">$</span>Fat</span></code></pre></div>
<div id="logistic-regression-model-glm-classif.glm" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Logistic Regression Model (GLM): <code>classif.glm</code><a href="functional-supervised-classification.html#logistic-regression-model-glm-classif.glm" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As a particular case of Generalized Linear Models, the logistic regression model models the posterior probability given <span class="math inline">\(\mathbf{d}\)</span> as</p>
<p><span class="math display">\[  p(Y=i|\mathcal{X}(t))=\log \left(\frac{p(Y=i|\mathcal{X}(t))}{1-p(Y=i|\mathcal{X}(t))}\right)=\alpha_i+ \left\langle \mathcal{X}_i(t),\beta_{i}(t)\right\rangle\]</span></p>
<p>where the curve <span class="math inline">\(\mathcal{X}(t)\)</span> is assigned to class <span class="math inline">\(i\)</span> if <span class="math inline">\(p(i|\mathcal{X})&gt;p(j|\mathcal{X}), j=1,\cdots, g, j\ne i\)</span>.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="functional-supervised-classification.html#cb157-1" tabindex="-1"></a>res.bin<span class="ot">=</span><span class="fu">fregre.glm</span>(Fat<span class="sc">~</span>x,ldat,<span class="at">family=</span><span class="fu">binomial</span>())</span>
<span id="cb157-2"><a href="functional-supervised-classification.html#cb157-2" tabindex="-1"></a>res.glm<span class="ot">&lt;-</span>fda.usc<span class="sc">:::</span><span class="fu">classif.glm</span>(Fat<span class="sc">~</span>x,<span class="at">data=</span>ldat)</span>
<span id="cb157-3"><a href="functional-supervised-classification.html#cb157-3" tabindex="-1"></a><span class="fu">summary</span>(res.glm)</span></code></pre></div>
<pre><code>##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## 0 1 
## 1 1 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##       0   1
##   0 138   0
##   1   0  77
## 
## -Probability of correct classification:  1</code></pre>
</div>
<div id="generalized-additive-models-gam-classif.gsam-and-classif.gkam" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Generalized Additive Models (GAM): <code>classif.gsam</code> and <code>classif.gkam</code><a href="functional-supervised-classification.html#generalized-additive-models-gam-classif.gsam-and-classif.gkam" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Generalized Additive Models (see <span class="citation">Wood (<a href="#ref-wood2004">2004</a>)</span>) relax the linearity assumption in GLMs, allowing the use of a sum of general smooth functions <span class="math inline">\(f_j\)</span> for the posterior probability; i.e.,</p>
<p><span class="math display">\[  p(Y=i|\mathcal{X}(t))=\log \left(\frac{p(Y=i|\mathcal{X}(t))}{1-p(Y=i|\mathcal{X}(t))}\right)=\alpha_i+  f_i\left(\mathcal{X}_{i}(t)\right)\]</span></p>
<p>where the functions <span class="math inline">\(f_{i}\)</span> may belong to a known parametric family (polynomials, for instance) or they may even be functions to be estimated non-parametrically.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="functional-supervised-classification.html#cb159-1" tabindex="-1"></a>res.gsam<span class="ot">&lt;-</span><span class="fu">classif.gsam</span>(Fat<span class="sc">~</span><span class="fu">s</span>(x),<span class="at">data=</span>ldat)</span>
<span id="cb159-2"><a href="functional-supervised-classification.html#cb159-2" tabindex="-1"></a><span class="fu">summary</span>(res.gsam)</span></code></pre></div>
<pre><code>##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## 0 1 
## 1 1 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##       0   1
##   0 138   0
##   1   0  77
## 
## -Probability of correct classification:  1</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="functional-supervised-classification.html#cb161-1" tabindex="-1"></a><span class="co">#res.gkam&lt;-classif.gkam(Fat~x,data=ldata)</span></span></code></pre></div>
</div>
<div id="nonparametric-classification-methods-classif.knn-and-classif.np-ferraty2003" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Nonparametric classification methods: <code>classif.knn</code> and <code>classif.np</code> <span class="citation">(<a href="#ref-Ferraty2003">Frédéric Ferraty and Vieu 2003</a>)</span><a href="functional-supervised-classification.html#nonparametric-classification-methods-classif.knn-and-classif.np-ferraty2003" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>These methods are based on non-parametric estimates of the densities of the groups. The most simple (and classical) one is <span class="math inline">\(k\)</span>–nearest neighbour (<span class="math inline">\(k\)</span>NN) in which, given <span class="math inline">\(k \in \mathbb{N}\)</span>, the point <span class="math inline">\(\mathbf{d}\)</span> is assigned to the class containing a majority of the <span class="math inline">\(k\)</span> nearest data points in the training sample.</p>
<p>Another possibility is to estimate <span class="math inline">\(p(Y=g|\mathcal{X})\)</span> through the Nadaraya–Watson estimator:</p>
<p><span class="math display">\[p(Y=g|\mathcal{X})=\frac{\sum_{n=1}^N \mathbf{1}_{G_n=g}\  K\left(m(\mathcal{X},\mathcal{X}_i(t))/h\right)}{\sum_{n=1}^N K\left(m(\mathcal{X}_i(t))/h\right)},\]</span></p>
<p>where <span class="math inline">\(N\)</span> is the size of the training sample, <span class="math inline">\(G_n\)</span> is the class of <span class="math inline">\(i\)</span>-th curve in the training sample, <span class="math inline">\(K\)</span> is a kernel and <span class="math inline">\(m(\cdot,\cdot )\)</span> is a measure of closeness between two curves (a suitable distancewhich is re-scaled by the bandwidth parameter <span class="math inline">\(h\)</span>) .</p>
<pre><code>## y
##         0         1 
## 0.8550725 0.7142857</code></pre>
<p>A <span class="math inline">\(k\)</span>NN method could be considered an NP method using the uniform kernel and a locally selected bandwidth.</p>
<pre><code>## y
##         0         1 
## 0.7826087 0.7012987</code></pre>
</div>
<div id="maximum-depth-classif.depth-li2012" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Maximum depth: <code>classif.depth</code> <span class="citation">(<a href="#ref-Li2012">Li, Cuesta-Albertos, and Liu 2012</a>)</span><a href="functional-supervised-classification.html#maximum-depth-classif.depth-li2012" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The most basic rule is to assign a new observation <span class="math inline">\(x_0\)</span> to the group that provides the highest depth to that observation (Maximum depth (MD)). The maximum depth classifier was the first attempt to use data depths instead of multivariate raw data to construct a classification rule.</p>
<p><strong>Perform the following example with hidden code</strong></p>
<p>Given a sample depth measure and a new observation <span class="math inline">\(x_0\)</span> (use the <code>xx.d1</code> curves):</p>
<ol style="list-style-type: decimal">
<li>Evaluate the depth of <span class="math inline">\(x_0\)</span> in both sub-samples defined by <code>ycat</code> variable (only the first 10 values are printed)</li>
</ol>
<pre><code>## Depth g1 0.4811594 0.164058 0.5717391 0.5602899 0.4068116 0.127971 0.1237681 0.7730435 0.3373913 0.2971014</code></pre>
<pre><code>## Depth g2 0.4811594 0.164058 0.5717391 0.5602899 0.4068116 0.127971 0.1237681 0.7730435 0.3373913 0.2971014</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Assign <span class="math inline">\(x_0\)</span> according to the data set where it is more deeply placed.</li>
</ol>
<pre><code>## group.est: 0 1 0 0 1 1 1 0 1 1</code></pre>
<pre><code>## ycat     : 1 1 0 0 1 1 1 0 0 0</code></pre>
<p>The function <code>classif.depth</code> performs previous tasks:</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="functional-supervised-classification.html#cb168-1" tabindex="-1"></a>res.depth<span class="ot">&lt;-</span><span class="fu">classif.depth</span>(ycat,x.d1,<span class="at">depth=</span><span class="st">&quot;FM&quot;</span>)</span>
<span id="cb168-2"><a href="functional-supervised-classification.html#cb168-2" tabindex="-1"></a><span class="fu">data.frame</span>(res.depth<span class="sc">$</span>dep,group.est,res.depth<span class="sc">$</span>dep<span class="sc">-</span><span class="fu">cbind</span>(d1,d2))[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,]</span></code></pre></div>
<pre><code>##           X1        X2 group.est d1 d2
## 1  0.4811594 0.4051948         0  0  0
## 2  0.1640580 0.4766234         1  0  0
## 3  0.5717391 0.2659740         0  0  0
## 4  0.5602899 0.2522078         0  0  0
## 5  0.4068116 0.5083117         1  0  0
## 6  0.1279710 0.3948052         1  0  0
## 7  0.1237681 0.3254545         1  0  0
## 8  0.7730435 0.3135065         0  0  0
## 9  0.3373913 0.4568831         1  0  0
## 10 0.2971014 0.4238961         1  0  0</code></pre>
</div>
<div id="the-ddgclassifier-classif.dd-cuesta2017hbox" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> The DD<span class="math inline">\(^G\)</span>–classifier <code>classif.DD</code> <span class="citation">(<a href="#ref-cuesta2017hbox">J. A. Cuesta-Albertos, Febrero-Bande, and Oviedo de la Fuente 2017</a>)</span><a href="functional-supervised-classification.html#the-ddgclassifier-classif.dd-cuesta2017hbox" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose that we have implementations of a process in the product space <span class="math inline">\(\mathcal{X}=\mathcal{X}_1\times\cdots\times\mathcal{X}_p\)</span> (multivariate (functional) data) where we have <span class="math inline">\(g\)</span> groups (classes or distributions) to be separated using data depths. The DD<span class="math inline">\(^G\)</span>–classifier begins by selecting a depth <span class="math inline">\(D\)</span> and computing the following map (for <span class="math inline">\(p=1\)</span>):</p>
<p><span class="math display">\[
\mathcal{ X} \rightarrow  \mathbb{R}^g
\\
x  \rightarrow \mathbb{d}=({D}_1(x),\cdots,{D}_g(x)).
\]</span></p>
<p>We can now apply any available classification procedure that works in a <span class="math inline">\(g\)</span>–dimensional space to separate the <span class="math inline">\(g\)</span> groups.</p>
<p>where <span class="math inline">\(D_0k(x)\)</span> is the depth of x with respect to the group <span class="math inline">\(k = 1,\cdots,g\)</span>.
So, the DDG -Classifier compresses the information of <span class="math inline">\({y_i,x_i}\)</span> into a real space of dimension <span class="math inline">\((g + 1)\)</span> with the form <span class="math inline">\(\left\{y_i,D_1(x_i),\cdots,D_g(x_i)\right\}\)</span>.</p>
<p>Classification techniques in <span class="math inline">\(\mathbb{R}^g\)</span>:</p>
<ol style="list-style-type: decimal">
<li>Linear Discriminant Analysis (LDA)</li>
<li>Quadratic Discriminant Analysis (QDA)</li>
<li>Generalized Linear Models (GLM)</li>
<li>Generalized Additive Models (GAM)</li>
<li>k-Nearest Neighbors (kNN)</li>
<li>Kernel Classification Method (NP)</li>
<li>Classification Trees (Tree)</li>
<li>ANN, SVMs, …</li>
</ol>
<p>The aim of the DD-classifier (<span class="citation">(<a href="#ref-Li2012">Li, Cuesta-Albertos, and Liu 2012</a>)</span>) is to extend the Maximum depth classifier using a polynomial up to degree k passing through the origin as classification rule.</p>
<p>The DD–classifier has resolved several serious limitations of the maximum depth classifier .</p>
<p>Properties of the DDG -classifier:</p>
<ol style="list-style-type: decimal">
<li><p>A lot of classification methods available (All in the multivariate framework)</p></li>
<li><p>Using classical classification methods in the DD-plot can provide useful insights about what’s going on (which depths are influential or probabilities of belonging to a certain group).</p></li>
<li><p>Possible reduction in the dimension of the classification problem, specially interesting in the Functional Framework (or in High Dimensional problems).</p></li>
<li><p>No matters how complex is the space to be analyzed, only matters that a depth function can be defined (for example, multivariate functional data MFD: <span class="math inline">\(\mathcal{X}=\mathcal{X}_1\times\cdots\times\mathcal{X}_p\)</span>.</p></li>
</ol>
<blockquote>
<p>Example DD with 2 groups</p>
</blockquote>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="functional-supervised-classification.html#cb170-1" tabindex="-1"></a>res.DD<span class="ot">&lt;-</span><span class="fu">classif.DD</span>(ycat,x.d1,<span class="at">classif=</span><span class="st">&quot;gam&quot;</span>,<span class="at">depth=</span><span class="st">&quot;mode&quot;</span>)</span></code></pre></div>
<p><img src="bookdown_intro_files/figure-html/unnamed-chunk-68-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="functional-supervised-classification.html#cb171-1" tabindex="-1"></a>res.depth<span class="sc">$</span>prob.classification</span></code></pre></div>
<pre><code>## group
##         0         1 
## 0.8260870 0.9350649</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="functional-supervised-classification.html#cb173-1" tabindex="-1"></a>res.DD<span class="sc">$</span>prob.classification</span></code></pre></div>
<pre><code>## group
##         0         1 
## 0.9782609 0.9610390</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="functional-supervised-classification.html#cb175-1" tabindex="-1"></a><span class="co">#res.DD</span></span></code></pre></div>
<blockquote>
<p>Example dDD with G groups</p>
</blockquote>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="functional-supervised-classification.html#cb176-1" tabindex="-1"></a><span class="co">#ycat&lt;-cut(ldata$df$Fat,3,labels=1:3) </span></span>
<span id="cb176-2"><a href="functional-supervised-classification.html#cb176-2" tabindex="-1"></a><span class="co"># DD-classif for functional data: G levels </span></span>
<span id="cb176-3"><a href="functional-supervised-classification.html#cb176-3" tabindex="-1"></a><span class="fu">data</span>(phoneme)</span>
<span id="cb176-4"><a href="functional-supervised-classification.html#cb176-4" tabindex="-1"></a>mlearn<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;learn&quot;</span>]]</span>
<span id="cb176-5"><a href="functional-supervised-classification.html#cb176-5" tabindex="-1"></a>mlearn2<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;test&quot;</span>]]</span>
<span id="cb176-6"><a href="functional-supervised-classification.html#cb176-6" tabindex="-1"></a>glearn<span class="ot">&lt;-</span><span class="fu">as.numeric</span>(phoneme[[<span class="st">&quot;classlearn&quot;</span>]])<span class="sc">-</span><span class="dv">1</span></span>
<span id="cb176-7"><a href="functional-supervised-classification.html#cb176-7" tabindex="-1"></a>out20<span class="ot">=</span><span class="fu">classif.DD</span>(glearn,mlearn,<span class="at">depth=</span><span class="st">&quot;mode&quot;</span>,<span class="at">classif=</span><span class="st">&quot;glm&quot;</span>)</span></code></pre></div>
<p><img src="bookdown_intro_files/figure-html/unnamed-chunk-69-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="functional-supervised-classification.html#cb177-1" tabindex="-1"></a>out21<span class="ot">=</span><span class="fu">classif.DD</span>(glearn,<span class="fu">list</span>(mlearn,mlearn2),<span class="at">depth=</span><span class="st">&quot;modep&quot;</span>,<span class="at">classif=</span><span class="st">&quot;glm&quot;</span>,<span class="at">control=</span><span class="fu">list</span>(<span class="at">draw=</span>F))</span>
<span id="cb177-2"><a href="functional-supervised-classification.html#cb177-2" tabindex="-1"></a>out20 <span class="co"># univariate functional data</span></span></code></pre></div>
<pre><code>## 
## -Call:
## classif.DD(group = glearn, fdataobj = mlearn, depth = &quot;mode&quot;,     classif = &quot;glm&quot;)
## 
## -Probability of correct classification:  0.928</code></pre>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="functional-supervised-classification.html#cb179-1" tabindex="-1"></a>out21 <span class="co"># multivariate functional data</span></span></code></pre></div>
<pre><code>## 
## -Call:
## classif.DD(group = glearn, fdataobj = list(mlearn, mlearn2),     depth = &quot;modep&quot;, classif = &quot;glm&quot;, control = list(draw = F))
## 
## -Probability of correct classification:  0.952</code></pre>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="functional-supervised-classification.html#cb181-1" tabindex="-1"></a><span class="co">#summary.classif(out21)</span></span></code></pre></div>
</div>
<div id="classifiers-adapted-from-multivariate-framework" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Classifiers adapted from Multivariate Framework<a href="functional-supervised-classification.html#classifiers-adapted-from-multivariate-framework" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The idea is to recycle all the procedures known in the Multivariate Frameworkconverting an object of infinite dimension into a finite dimension.
When to apply:
+ The basis is enough for accounting all information.
+ Binary/multiclass problems depends on multivariate classifier method.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="functional-supervised-classification.html#cb182-1" tabindex="-1"></a><span class="fu">data</span>(phoneme)</span>
<span id="cb182-2"><a href="functional-supervised-classification.html#cb182-2" tabindex="-1"></a>ldat<span class="ot">=</span><span class="fu">ldata</span>(<span class="st">&quot;df&quot;</span><span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">glearn=</span>phoneme<span class="sc">$</span>classlearn),<span class="st">&quot;x&quot;</span><span class="ot">=</span>phoneme<span class="sc">$</span>learn)</span>
<span id="cb182-3"><a href="functional-supervised-classification.html#cb182-3" tabindex="-1"></a><span class="co"># require e1071 package</span></span>
<span id="cb182-4"><a href="functional-supervised-classification.html#cb182-4" tabindex="-1"></a>res.svm<span class="ot">=</span><span class="fu">classif.svm</span>(glearn<span class="sc">~</span>x,<span class="at">data=</span>ldat)</span>
<span id="cb182-5"><a href="functional-supervised-classification.html#cb182-5" tabindex="-1"></a><span class="co"># require nnet package</span></span>
<span id="cb182-6"><a href="functional-supervised-classification.html#cb182-6" tabindex="-1"></a>res.nnet<span class="ot">=</span><span class="fu">classif.nnet</span>(glearn<span class="sc">~</span>x,<span class="at">data=</span>ldat,<span class="at">trace=</span><span class="cn">FALSE</span>)</span>
<span id="cb182-7"><a href="functional-supervised-classification.html#cb182-7" tabindex="-1"></a><span class="co"># require rpart package</span></span>
<span id="cb182-8"><a href="functional-supervised-classification.html#cb182-8" tabindex="-1"></a>res.rpart<span class="ot">=</span><span class="fu">classif.rpart</span>(glearn<span class="sc">~</span>x,<span class="at">data=</span>ldat)</span>
<span id="cb182-9"><a href="functional-supervised-classification.html#cb182-9" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(res.svm<span class="sc">$</span>prob.classification),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.904</code></pre>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="functional-supervised-classification.html#cb184-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(res.nnet<span class="sc">$</span>prob.classification),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.888</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="functional-supervised-classification.html#cb186-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(res.rpart<span class="sc">$</span>prob.classification),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.896</code></pre>
<p>Add utilities in the classification functions: for example, majority voting scheme (by default ONE vs REST). R example (work in progress)</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="functional-supervised-classification.html#cb188-1" tabindex="-1"></a>ii<span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>,<span class="dv">51</span><span class="sc">:</span><span class="dv">60</span>,<span class="dv">101</span><span class="sc">:</span><span class="dv">110</span>,<span class="dv">151</span><span class="sc">:</span><span class="dv">160</span>,<span class="dv">201</span><span class="sc">:</span><span class="dv">250</span>)</span>
<span id="cb188-2"><a href="functional-supervised-classification.html#cb188-2" tabindex="-1"></a>mlearn<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;learn&quot;</span>]][ii];glearn<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;classlearn&quot;</span>]][ii]</span>
<span id="cb188-3"><a href="functional-supervised-classification.html#cb188-3" tabindex="-1"></a>mtest<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;test&quot;</span>]];gtest<span class="ot">&lt;-</span>phoneme[[<span class="st">&quot;classtest&quot;</span>]]</span>
<span id="cb188-4"><a href="functional-supervised-classification.html#cb188-4" tabindex="-1"></a>dataf<span class="ot">&lt;-</span><span class="fu">data.frame</span>(glearn);ldat<span class="ot">=</span><span class="fu">ldata</span>(<span class="st">&quot;df&quot;</span><span class="ot">=</span>dataf,<span class="st">&quot;x&quot;</span><span class="ot">=</span>mlearn);newdat<span class="ot">&lt;-</span><span class="fu">list</span>(<span class="st">&quot;x&quot;</span><span class="ot">=</span>mtest)</span>
<span id="cb188-5"><a href="functional-supervised-classification.html#cb188-5" tabindex="-1"></a>a1<span class="ot">&lt;-</span><span class="fu">classif.glm</span>(glearn<span class="sc">~</span>x, <span class="at">data =</span> ldat)</span>
<span id="cb188-6"><a href="functional-supervised-classification.html#cb188-6" tabindex="-1"></a>a2<span class="ot">&lt;-</span><span class="fu">classif.glm</span>(glearn<span class="sc">~</span>x, <span class="at">data =</span> ldat,<span class="at">type=</span><span class="st">&quot;majority&quot;</span>)</span>
<span id="cb188-7"><a href="functional-supervised-classification.html#cb188-7" tabindex="-1"></a>a3<span class="ot">&lt;-</span><span class="fu">classif.glm</span>(glearn<span class="sc">~</span>x, <span class="at">data =</span> ldat,<span class="at">type=</span><span class="st">&quot;majority&quot;</span>,<span class="at">weights=</span><span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">4</span>,<span class="at">len=</span><span class="dv">40</span>),<span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">50</span>)))</span>
<span id="cb188-8"><a href="functional-supervised-classification.html#cb188-8" tabindex="-1"></a><span class="co"># mean(predict(a1,newdat)==gtest);mean(predict(a2,newdat)==gtest);mean(predict(a3,newdat)==gtest)</span></span></code></pre></div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-cuesta2017hbox" class="csl-entry">
Cuesta-Albertos, Juan A, Manuel Febrero-Bande, and Manuel Oviedo de la Fuente. 2017. <em>Test</em> 26 (1): 119–42.
</div>
<div id="ref-Ferraty2003" class="csl-entry">
Ferraty, Frédéric, and Philippe Vieu. 2003. <span>“Curves Discrimination: A Nonparametric Functional Approach.”</span> <em>Comput. Statist. Data Anal.</em> 44 (1): 161–73. <a href="http://www.sciencedirect.com/science/article/pii/S016794730300032X">http://www.sciencedirect.com/science/article/pii/S016794730300032X</a>.
</div>
<div id="ref-Li2012" class="csl-entry">
Li, Jun, Juan A Cuesta-Albertos, and Regina Y Liu. 2012. <span>“<span class="math inline">\(DD\)</span>–Classifier: Nonparametric Classification Procedure Based on <span class="math inline">\(DD\)</span>–Plot.”</span> <em>J. Amer. Statist. Assoc.</em> 107 (498): 737–53. <a href="http://amstat.tandfonline.com/doi/abs/10.1080/01621459.2012.688462">http://amstat.tandfonline.com/doi/abs/10.1080/01621459.2012.688462</a>.
</div>
<div id="ref-wood2004" class="csl-entry">
Wood, Simon N. 2004. <span>“Stable and Efficient Multiple Smoothing Parameter Estimation for Generalized Additive Models.”</span> <em>Journal of the American Statistical Association</em> 99 (467): 673–86.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="variable-selection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/moviedo5/bookdown_fda_usc/edit/master/03-classification.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown_intro.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
